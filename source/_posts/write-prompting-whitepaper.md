---
title: Google/Kaggle Whitepaper Prompt Engineering
categories: 
- Writing
class: Writing
date: 2024-11-11 12:00:00
description: 
tags:
  - Gemini
  - Prompt Engineering
  - Prompts
  - LLM
  - Large Language Models
hidden: true
---

Whitepaper Prompt Engineering by Lee Boonstra
When thinking about a large language model input and output, a text prompt (sometimes accompanied by other modalities such as image prompts) is the input the model uses to predict a specific output. You don’t need to be a data scientist or a machine learning engineer – everyone can write a prompt. However, crafting the most effective prompt can be complicated. Many aspects of your prompt affect its efficacy: the model you use, the model’s training data, the model configurations, your word-choice, style and tone, structure, and context all matter. Therefore, prompt engineering is an iterative process. Inadequate prompts can lead to ambiguous, inaccurate responses, and can hinder the model’s ability to provide meaningful output. You don’t need to be a data scientist or a machine learning engineer – everyone can write a prompt.
When you chat with the Gemini chatbot, you basically write prompts, however this whitepaper focuses on writing prompts for the Gemini model within Vertex AI or by using the API, because by prompting the model directly you will have access to the configuration such as temperature etc.
This whitepaper discusses prompt engineering in detail. We will look into the various prompting techniques to help you getting started and share tips and best practices to become a prompting expert. We will also discuss some of the challenges you can face while crafting prompts.

Read my Prompt Engineering whitepaper on Kaggle: https://www.kaggle.com/whitepaper-prompt-engineering

<!-- more --> 

